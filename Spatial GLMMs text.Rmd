---
title: "Fitting Gaussian mixed effects models to spatially autocorrelated data"
author: "Jeroen Minderman"
date: "Tuesday, December 02, 2014"
output: 
  html_document:
    theme: journal
---

```{r echo=F, results='hide', message=F, warning=F}
source('helpjm.r')
```

## Background
  
The usual approach to fitting linear models to data that exhibit spatial autocorrelation is to include variance structures that account for any residual correlation **[REF]**. This is usually illustrated using data without any additional error terms or correlated errors (that is, using conventional general or generalised linear models), and the presence (or absence) of any spatial correlation in the residuals can be easily assessed using variograms and/or "bubble" plots of the residuals.  
By contrast, when a data set not only exhibits spatial autocorrelation, but also contains correlations that are caused by e.g. multiple measures from individuals, groups or sites, things become more complicated. Independence of errors due to repeated measures from groups (or individuals, or sites) is commonly dealt with by including a random term, yielding a mixed effects model (GLMM). Although methods exist to fit GLMMs with additional spatial autocorrelation accounted for **[REF]**, interpretation of both variograms and "bubble" plots of residuals is not as intuitive as in "simple" linear models, making the identification of the presence of residual spatial autocorrelation challenging. Moreover, it is possible that in some cases the random effect terms to a large extent masks or 'mops up' all of the variation that would otherwise be accounted for by the spatial correlation. For example, if measurements are taken at a number of locations within a number of sites (so that measurements within sites are spatially clustered, and physically closer to each other than measurements from different sites) the repeated measurements per site could be accounted for by including a random effect for site. Any remaining spatial autocorrelation *within* each site could and should be accounted for by an additional spatial correlation structure. However, if measurements are "clustered" within sites, it is possible that any such remaining spatial autocorrelation -even if present- is difficult detect, and therefore likely to be missed.  
Here, we provide examples of how and when residual spatial autocorrelation may be difficult to detect when fitting GLMMs, and suggest approaches that avoid common pitfalls when doing so. Specifically, we aim to assess: 

1. How the degree of spatial clustering (as well as the strength of the autocorrelation relative to the clustering) can affect the ability to detect residual spatial correlation;    
2. The importance of within-group (or within-site) sample size in the ability to detect residual spatial autocorrelation.    

To address the above aims, we generate simulated mixed-effect data with a single random effect (groups or sites) and with and without additional spatial correlation of known strength. In addition, we can either cluster individual observations within sites (referred to as the "clustered" scenario below) or keep the random term entirely independent of the spatial correlation (referred to as the "independent" scenario below). Whereas the former scenario is best visualised as individual measurements spatially clustered within sites, the latter scenario could represent for example repeated measurements of a number of individuals through space, where measurements taken of any individual are more likely to be similar when closer together in space.  
Finally, we make a number of practical recommendations for the analysis of spatially correlated "mixed effects" data.  

## Simulations and Results
  
### Linear model data with spatial autocorrelation

To illustrate a basic data set with spatial autocorrelated errors but without further random effects, we first simulate $N$ measurements $y_i$ as a linear function of some predictor variable $X_i$ with common intercept $b_1$=1 and slope $b_2$=2, and two error terms: one residual error term $a_1,i$ and one spatial error term $a_2,i$
 
$y_i = b_1 + b_2X_i + a_{1,i} + a_{2,i}$
 
Where the residual error term $a_{1,i}$ is normally distributed with mean $\mu$=0 and standard deviation $\sigma_{\epsilon}$=1:  
 
$a_1 ~ N(\mu = 0, \sigma_{\epsilon} = 1)$  
 
And the spatial error term $a_{2,i}$ is drawn from a multivariate normal distribution with mean 0 and covariance matrix $\Sigma$ equal to:  
 
$\Sigma = exp(-\rho d)\sigma_s^2$ 
 
Where $d$ is a matrix of distances between observations (randomly drawn 'coordinates' x_c and y_c for each observation), so that the strength of the correlation between two observations decreases exponentially with distance and parameter $\rho$, and $\sigma_s^2$ is the spatial error variance. Data is simulated as follows:  

```{r}
source('helpjm.r')
library(MASS)
N <- 500
b_1 <- 1
b_2 <- 2
e <- 1
e_sp <- 1
rho <- 0.01
mydat <- data.frame('xc'=runif(N, 0, 1000), 
                    'yc'=runif(N, 0, 1000),
                    'X_i'=runif(N, 0, 5))
a_1 <- rnorm(N, mean=0, sd=e)
d <- with(mydat, as.matrix(dist(cbind(xc,yc))))
a_2 <- mvrnorm(1, rep(0,N), exp(-rho*d)*e_sp^2)
mydat$y_i <- b_1 + b_2*mydat$X_i + a_1 + a_2

```
``` {r echo=FALSE, warning=FALSE}
library(knitr)
par(mfrow=c(1,2))
with(mydat, plot(X_i, y_i))
with(mydat, plotbubble(xc, yc, y_i, xlab='X coordinate', ylab='Y coordinate', colsign=FALSE, size=0.5))
```  

To illustrate the consequences of ignoring the spatial structure in the data, we fit a simple linear model:  
``` {r}
mod1 <- lm(y_i ~ X_i, data=mydat)
summary(mod1)$coef
```
 
Residual spatial correlation can be clearly detected using both a "bubble" plot of the residuals, as well as a variogram of the residuals. This could be addressed by fitting an appropriate model that can include specific variance structures to accomodate spatial dependence (e.g. gls *[REF]*).
 
``` {r, echo=FALSE, warning=FALSE}
library(gstat)
library(sp)
mydat$res1 <- resid(mod1)
par(mfrow=c(1,2))
with(mydat, plotbubble(xc, yc, res1))
coordinates(mydat) <- c('xc','yc')
with(mydat, plotvario(variogram(res1 ~ 1, data=mydat)))
```
 
