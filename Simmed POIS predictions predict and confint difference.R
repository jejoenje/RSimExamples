### So what is the difference between the SE from predict() and the predictions
###  generated by looking at confint() upper and lower parameter levels??

### First generate some poisson data Y as function of sole explanatory variable X.
# Function with simulation algorithm:
source('sim_pois.r')
# Number of simulated observations:
n_obs <- 500
# Vector of 'true' parameters, one intercept, one slope.
b <- c(-1,1)
# Upper and lower values of X (simulation draws random X's between these):
x_lo <- 2
x_hi <- 4
# Simulate the data with above parameterS:
mydat <- sim_pois(n_obs=n_obs, x_lo=x_lo, x_hi=x_hi, b=b)
# Now plot simulated Y against X:
par(mfrow=c(1,1))
plot(y ~ x, data=mydat)
# Fit GLM model with Poisson errors:
mod <- glm(y ~ x, data=mydat, family='poisson')
# The parameter estimates look good:
summary(mod)
# Generate some new X data to to predict from between the same upper and lower
#  levels as above:
nwx <- data.frame(x=seq(x_lo,x_hi,(x_hi-x_lo)/100))
# Make predictions using predict() with SE's included:
pred <- predict(mod, newdata=nwx, type='response', se=T)
# Plot this prediction +/- 2* the reported SE:
lines(nwx$x, pred$fit, lwd=2, col='red')
lines(nwx$x, pred$fit+2*pred$se, lwd=1, col='red', lty='dashed')
lines(nwx$x, pred$fit-2*pred$se, lwd=1, col='red', lty='dashed')
# Note that these are very narrow relative to the data variability.
# Now plot the same predicted upper and lower values but using the 95% upper and lower CI
#  from confint():
ci <- confint(mod)
lines(nwx$x, exp(model.matrix(~x, data=nwx) %*% ci[,1]), col='blue')
lines(nwx$x, exp(model.matrix(~x, data=nwx) %*% ci[,2]), col='blue')

### 
### YIKES!!!
### 

### Try simulation-approach from sim()
library(arm)
mod_sim <- sim(mod, 1000)
coef_sim <- coef(mod_sim)
nwxmat <- model.matrix(~x, data=nwx)
preds <- as.data.frame(NULL)
for (i in 1:nrow(coef_sim)) {
  preds <- rbind(preds, t(exp(nwxmat %*% coef_sim[i,])))
}
pred2_mn <- apply(preds,2,mean)
pred2_lo <- apply(preds,2,function(x) quantile(x, probs=c(0.025)))
pred2_hi <- apply(preds,2,function(x) quantile(x, probs=c(0.975)))

lines(nwx$x, pred2_mn, col='darkgreen', lwd=2)
lines(nwx$x, pred2_lo, col='darkgreen', lwd=2, lty='dotdash')
lines(nwx$x, pred2_hi, col='darkgreen', lwd=2, lty='dotdash')

### Very surprisingly, from the above, it seems that the sim() approach 
###  yields the exact same predictions as the SE from predict() approach does.

# Have a look at the histograms of the parameter estimates from sim() as well
#  as 'model' histograms based on the point estimate and the SE taken as SD:
par(mfrow=c(1,2))
par1 <- rnorm(1000, mean=summary(mod)$coef[1,'Estimate'], sd=summary(mod)$coef[1,'Std. Error'])
par2 <- rnorm(1000, mean=summary(mod)$coef[2,'Estimate'], sd=summary(mod)$coef[2,'Std. Error'])
par1_sim <- coef_sim[,1]
par2_sim <- coef_sim[,2]
### Very quick 'homebrew' attempt at simulation from MV normal distribution
###  with means as the point estimates and co-variance from model vcov.
library(mvtnorm)
mysims <- rmvnorm(5000, coef(mod), vcov(mod))
plot(density(par1))
lines(density(par1_sim), col='red')
lines(density(mysims[,1]), col='darkgreen')
plot(density(par2))
lines(density(par2_sim), col='red')
lines(density(mysims[,2]), col='darkgreen')

###http://glmm.wikidot.com/faq

K <- 5000
coef_sim <- rmvnorm(K, coef(mod), vcov(mod))
nwx_frame <- data.frame(x=seq(x_lo, x_hi, (x_hi-x_lo)/100))
nwx <- model.matrix(~x, data=nwx_frame)
preds <- as.data.frame(NULL)
for (k in 1:K) {
  mu <- exp(nwx %*% coef_sim[k,])
  preds <- rbind(preds, rpois(length(mu),lambda=mu))
}
p_mn <- as.vector(apply(preds, 2, mean))
p_sd <- as.vector(apply(preds, 2, sd))
p_lo <- p_mn-p_sd*1.96
p_hi <- p_mn+p_sd*1.96
x <- seq(x_lo, x_hi, (x_hi-x_lo)/100)
plot(mydat$x, mydat$y)
lines(x, p_mn, lwd=3, col='red')
lines(x, p_lo, lwd=1, col='red')
lines(x, p_hi, lwd=1, col='red')
